environment = dev
kafka.default.bootstrap.servers = quickstart-bigdata:9092
spark.default.database = 1357_disp_${environment}
spark.fileSize.minimum.bytes = 67108864
spark.smallFile.maximum = 1
spark.log.table.ingestion = ${spark.default.database}.t_spark_ingestion_log
spark.log.table.fileMerger = t_file_merger_log
spark.output.tmp.path = /user/osboxes/tmp/output/disp_spark_streaming
spark.saveMode.append = Append

impala.driver.className = com.cloudera.impala.jdbc.Driver
impala.jdbc.url = jdbc:impala://quickstart-bigdata:21050;AuthMech=0;

yarn.logs.ui.url = http://quickstart-bigdata:8088/cluster/app

################
##### JOBS #####
################

# Webdisp
webdisp.kafka.bootstrap.servers = ${kafka.default.bootstrap.servers}
webdisp.kafka.group.id = webdisp_${environment}
webdisp.kafka.topic.name = 1357-disp-webdisp-${environment}
webdisp.kafka.topic.partition = 0
webdisp.kafka.auto.offset.reset = earliest
webdisp.kafka.max.poll.records = 24
webdisp.spark.target.table = ${spark.default.database}.t_ingested_webdisp

# Jarvis
jarvis.kafka.bootstrap.servers = ${kafka.default.bootstrap.servers}
jarvis.kafka.group.id = jarvis_${environment}
jarvis.kafka.topic.name = 1357-disp-jarvis-${environment}
jarvis.kafka.topic.partition = 0
jarvis.kafka.auto.offset.reset = earliest
jarvis.kafka.max.poll.records = 24
jarvis.spark.target.table = ${spark.default.database}.t_ingested_jarvis

# Int002
int002.kafka.bootstrap.servers = ${kafka.default.bootstrap.servers}
int002.kafka.group.id = int002_${environment}
int002.kafka.topic.name = 1357-disp-int002-${environment}
int002.kafka.topic.partition = 0
int002.kafka.auto.offset.reset = earliest
int002.kafka.max.poll.records = 24
int002.spark.target.table = ${spark.default.database}.t_ingested_int002

# Conduzione
conduzione.kafka.bootstrap.servers = ${kafka.default.bootstrap.servers}
conduzione.kafka.group.id = conduzione_${environment}
conduzione.kafka.topic.name = 1357-disp-conduzione-${environment}
conduzione.kafka.topic.partition = 0
conduzione.kafka.auto.offset.reset = earliest
conduzione.kafka.max.poll.records = 24
conduzione.spark.target.table = ${spark.default.database}.t_ingested_conduzione